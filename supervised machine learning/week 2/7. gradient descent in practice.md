**Question 1**<br>
![image](https://github.com/user-attachments/assets/02baf3f2-ae2b-49d4-a533-8388be50666f)<br>
Which of the following is a valid step used during feature scaling? 
- [x] Subtract the mean (average) from each value and then divide by the (max - min).
- [ ] Add the mean (average) from each value and and then divide by the (max - min).

**Question 2**<br>
Suppose a friend ran gradient descent three separate times with three choices of the learning rate α and plotted the learning curves for each (cost J for each iteration).<br>
![image](https://github.com/user-attachments/assets/f1edd85f-778d-43ea-affb-1f00746550e2)<br>
For which case, A or B, was the learning rate α likely too large?
- [ ] case A only 
- [ ] Neither Case A nor B 
- [x] case B only
- [ ] Both Cases A and B

**Question 3**<br>
Of the circumstances below, for which one is feature scaling particularly helpful?
- [x] Feature scaling is helpful when one feature is much larger (or smaller) than another feature.
- [ ] Feature scaling is helpful when all the features in the original data (before scaling is applied) range from 0 to 1.

**Question 4**<br>
You are helping a grocery store predict its revenue, and have data on its items sold per week, and price per item. What could be a useful engineered feature?
- [ ] For each product, calculate the number of items sold divided by the price per item.
- [x] For each product, calculate the number of items sold times price per item.

**Question 5**<br>
True/False? With polynomial regression, the predicted values f_w,b(x) does not necessarily have to be a straight line (or linear) function of the input feature x.
- [ ] False 
- [x] True
