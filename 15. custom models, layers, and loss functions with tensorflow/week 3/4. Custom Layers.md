**Question 1**<br>
Lambda layer allows to execute an arbitrary function only within a Sequential API model.
- [x] False
- [ ] True

**Question 2**<br>
Which one of the following is the correct syntax for mapping an increment of 2 to the value of “x” using a Lambda layer? (tf = Tensorflow)
- [ ] tf.keras.layers.Lambda(x: tf.math.add(x, 2.0))
- [ ] tf.keras.Lambda(x: tf.math.add(x, 2.0))
- [ ] tf.keras.layers(lambda x: tf.math.add(x, 2.0))
- [x] tf.keras.layers.Lambda(lambda x: tf.math.add(x, 2.0))

**Question 3**<br>
One drawback of Lambda layers is that you cannot call a custom built function from within them.
- [ ] True
- [x] False

**Question 4**<br>
A Layer is defined by having “States” and “Computation”. Consider the following code and check all that are true:<br>
![image](https://github.com/user-attachments/assets/65d6c200-5a76-4e0a-bf35-7a0bc7264444)
- [ ] In def __init__(self, units=32): you use the super keyword to initialize all of the custom layer attributes
- [ ] def call(self, inputs): performs the computation and is called when the Class is instantiated.
- [ ] After training, this class will return a w*X + b computation, where X is the input, w is the weight/kernel tensor with trained values, and b is the bias tensor with trained values.
- [x] You use def build(self, input_shape): to create the state of the layers and specify local input states.

**Question 5**<br>
Consider the following code snippet.<br>
![image](https://github.com/user-attachments/assets/639f5805-59ee-4983-983d-563ef3fb7a73)<br>
What are the function modifications that are needed for passing an activation function to this custom layer implementation? 
- [x] def __init__(self, units=32, activation=None):<br>
          .<br>
          .<br>
          self.activation = tf.keras.activations.get(activation)<br>
      def call(self, inputs):<br> 
         return self.activation(tf.matmul(inputs, self.w) + self.b)
- [ ] def __init__(self, units=32):<br>
          .<br>
          .<br>
          self.activation = tf.keras.activations.get(activation)<br>
       def call(self, inputs):<br>
          return self.activation(tf.matmul(inputs, self.w) + self.b)
- [ ] def build(self, units=32, activation=None):<br>
          .<br>
          .<br>
          self.activation = activation<br> 
      def call(self, inputs):<br> 
         return self.activation(tf.matmul(inputs, self.w) + self.b)
- [ ] def build(self, input_shape):<br>
         .<br>
         .<br>
         self.activation = tf.keras.activations.get(activation)<br> 
      def call(self, inputs):<br> 
         return self.activation(tf.matmul(inputs, self.w) + self.b)
