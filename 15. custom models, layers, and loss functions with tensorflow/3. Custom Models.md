**Question 1**<br>
Following is an example of a deep and wide network structure.<br>
![image](https://github.com/user-attachments/assets/969b52b2-a9d9-4a02-b4be-c117f70090ec)
- [ ] True
- [x] False

**Question 2**<br>
Consider the following code and check all that are true:<br>
![image](https://github.com/user-attachments/assets/a865ea4d-c317-4969-919d-f5b7b6e8b183)
- [ ] The code is incomplete in the sense that you can only initialize and construct your model, you cannot perform training or inference.
- [x] The output layers cannot give more than 1 result each.
- [ ] The concat should be defined within the init function instead of the call function as it is also a hidden layer.
- [x] The init function initializes the MyModel Class objects, as well as the attributes that are inherited from the Model Class.

**Question 3**<br>
You have learned that Sequential and Functional APIs have their limitations.<br>
How can you build dynamic networks where the architecture changes on the fly, or networks where recursion is used? Check all that are true:
- [x] Using model subclassing
- [ ] Using Sequential API
- [x] Using Functional API

**Question 4**<br>
Which one of the following is a false statement regarding model subclassing?
- [ ] You can make use of Functional and Sequential APIs when writing code for model subclassing.
- [ ] Instead of tweaking the entire architecture, you can have different modules and make changes in them as required, as opposed to entirely rewriting the structure.
- [x] You cannot introduce a branch structure in the architecture when doing model subclassing.
- [ ] You can have modular architectures

**Question 5**<br>
Consider the following two images:<br>
![image](https://github.com/user-attachments/assets/a051a8d4-5ddf-4940-aa33-09d54f120638)<br>
![image](https://github.com/user-attachments/assets/30c6a26f-34e2-43ea-8089-dfb1fef72cb0)<br>
Check all that are true:
- [ ] You loop Residual Type 2 (Dense layers) because you cannot make a loop of Conv2D layers (Residual Type 1)
- [x] You make a loop of Residual Type 2 blocks because you want to reduce the depth of the network (making it less complex of an architecture)
- [x] When you make a loop of Residual Type 2 blocks, each block could have the same weights. 
- [x] Each Residual block has two hidden layers and one add layer in it.
