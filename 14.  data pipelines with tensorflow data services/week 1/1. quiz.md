**Question 1**<br>
Which of the following are correct about the Extract, Transform, Load (ETL) procedure?  
- [x] Transform phase involves data normalization and scaling  
- [x] Extract phase involves downloading a zip file from any external source containing the data  
- [ ] Extract phase would involve splitting the data into training and test sets  
- [ ] Load phase involves loading the a pre-trained model into the workspace  

**Question 2**<br>
What does the following code block achieve?
```
tfds.load(name="mnist", split="train")
```
- [ ] Loads mnist labels and assign them to any training dataset
- [x] Downloads and extracts training records from the mnist dataset  
- [ ] Extracts the mnist training dataset from a zip file  
- [ ] Splits the downloaded mnist data into train and test sets

**Question 3**<br>
Can you explore 10 records from the dataset by loading them into an iterator like this?
```
iterator = dataset.take(10)
```
- [x] Yes
- [ ] No

**Question 4**<br>
What is the role of the tfds.list_builders() function?  
- [ ] To build a list of multiple datasets to load at a time  
- [x] To return string names of all available datasets in Tensorflow 
- [ ] To create an empty dataset for creating a custom dataset  
- [ ] To return a list of files in the dataset  

**Question 5**<br>
How would you inspect the metadata and the details of a TensorFlow dataset?  
- [ ] Load the data using tfds.load() with the parameter as_supervised=False , and then inspect the DataSetInfo property
- [ ] There’s no API for this, read the docs instead
- [x] Load the data using tfds.load() with the parameter with_info=true, and then inspect the DataSetInfo property
- [ ] Load the data using tfds.load() with the parameter with_info=true, and then inspect the showCoreData property.

**Question 6**<br>
Which of the following ways are used to load mnist dataset with major version 1, minor version 2 and any patch version ?
- [x] Specify the exact version for a patch version in the load parameter like this: tfds.load(“mnist:1.2.1”)
- [ ] Specify the desired version as a split, like this: tfds.load(name=”mnist”, split=”1.*.*”)
- [ ] You’ll need to install the matching version of TFDS that installs that dataset, and then load it
- [x] Specify the desired version with asterisk in patch version in the string in the load parameter like this: tfds.load(“mnist”).version(“1.2.*”)

**Question 7**<br>
The fashion MNIST is a relatively simple example of a dataste used in computer vision modelling tasks used with or without TFDS. If you load the data using TensorFlow Keras datasets in TensorFlow 2.0 and above, what would the code look like? 
- [ ] data = tfds.as_numpy(tfds.load('fashion_mnist',<br>
      split =['train','test'],<br>
      batch_size=-1,<br>
      as_supervised=True))<br>
      (training_images,training_labels) , (test_images,test_labels) = data

- [x] data = tf.keras.dataset.fashion_mnist<br>
      (training_images,training_labels),(test_images,test_labels) = data.load_data()


- [ ] data = tf.keras.as_numpy(fashion_mnist)<br>
      (training_images,training_labels) , (test_images,test_labels) = data.load_data()


- [ ] data = keras.dataset.fashion_mnist<br>
      (training_images,training_labels) , (test_images,test_labels) = data.load_data()

**Question 8**<br>
Which of the following code blocks would successfully create "Horses and Humans" test batches of 10 by shuffling 100 data samples?  

- [ ] data = tfds.load('horses_or_humans',split = 'train', as_supervised=True)<br>
      batches = data.shuffle(100).batch(10)

- [x] data = tfds.load('horses_or_humans',split = 'test', as_supervised=True)<br>
      batches = data.shuffle(100).batch(10)

- [ ] data = tfds.load('horses_or_humans',split = 'test', as_supervised=False)<br>
      batches = data.shuffle(100).batch(10)

- [ ] data = tfds.load('horses_or_humans',split = 'test', as_supervised=True)<br>
      batches = data.shuffle(batch(100),10)
