**Question 1**<br>
You are using reinforcement learning to control a four legged robot. The position of the robot would be its _____.
- [ ] action 
- [ ] return 
- [x] state 
- [ ] reward

**Question 2**<br>
You are controlling a Mars rover. You will be very very happy if it gets to state 1 (significant scientific discovery), slightly happy if it gets to state 2 (small scientific discovery), and unhappy if it gets to state 3 (rover is permanently damaged). To reflect this, choose a reward function so that:
- [ ] R(1) > R(2) > R(3), where R(1), R(2) and R(3) are positive. 
- [ ] R(1) < R(2) < R(3), where R(1) and R(2) are negative and R(3) is positive. 
- [x] R(1) > R(2) > R(3), where R(1) and R(2) are positive and R(3) is negative. 
- [ ] R(1) > R(2) > R(3), where R(1), R(2) and R(3) are negative. 

**Question 3 **<br>
You are using reinforcement learning to fly a helicopter. Using a discount factor of 0.75, your helicopter starts in some state and receives rewards -100 on the first step, -100 on the second step, and 1000 on the third and final step (where it has reached a terminal state). What is the return?
- [x] -100 - 0.75*100 + 0.75^2*1000 
- [ ] -0.75*100 - 0.75^2*100 + 0.75^3*1000 
- [ ] -100 - 0.25*100 + 0.25^2*1000 
- [ ] -0.25*100 - 0.25^2*100 + 0.25^3*1000 

**Question 4**<br>
Given the rewards and actions below, compute the return from state 3 with a discount factor of Î³=0.25.<br>
![Screenshot_46](https://github.com/user-attachments/assets/4cffdeb6-5ef6-493e-ac07-d6f36801b0ea)
- [ ] 25 
- [x] 6.25
- [ ] 0 
- [ ] 0.39
