**Question 1**<br>
Which of these best describes unsupervised learning?<br>
- [ ] A form of machine learning that finds patterns without using a cost function.
- [ ] A form of machine learning that finds patterns in data using only labels (y) but without any inputs (x).
- [ ] A form of machine learning that finds patterns using labeled data (x, y) 
- [x] A form of machine learning that finds patterns using unlabeled data (x). 

**Question 2**<br>
Which of these statements are true about K-means? Check all that apply.
- [ ] The number of cluster centroids μ_k is equal to the number of examples.
- [x] The number of cluster assignment variables c^(i) is equal to the number of training examples.
- [x] If each example x is a vector of 5 numbers, then each cluster centroid μ_k is also going to be a vector of 5 numbers.
- [x] If you are running K-means with K=3 clusters, then each c^(i) should be 1, 2, or 3. 

**Question 3**<br>
You run K-means 100 times with different initializations. How should you pick from the 100 resulting solutions?
- [x] Pick the one with the lowest cost J
- [ ] Pick randomly -- that was the point of random initialization.
- [ ] Average all 100 solutions together. 
- [ ] Pick the last one (i.e., the 100th random initialization) because K-means always improves over time

**Question 4**<br>
You run K-means and compute the value of the cost function ![Screenshot_46](https://github.com/user-attachments/assets/66f338c2-6e4e-4346-a6ed-17206d787ca1) after each iteration. Which of these statements should be true? 
- [x] The cost will either decrease or stay the same after each iteration.
- [ ] There is no cost function for the K-means algorithm.
- [ ] Because K-means tries to maximize cost, the cost is always greater than or equal to the cost in the previous iteration
- [ ] The cost can be greater or smaller than the cost in the previous iteration, but it decreases in the long run.

**Question 5**<br>
In K-means, the elbow method is a method to 
- [ ] Choose the best number of samples in the dataset
- [ ] Choose the best random initialization
- [ ] Choose the maximum number of examples for each cluster
- [x] Choose the number of clusters K
