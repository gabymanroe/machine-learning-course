**Question 1**<br>
Whatâ€™s the primary difference between a simple RNN and an LSTM
- [x] In addition to the H output, LSTMs have a cell state that runs across all cells 
- [ ] LSTMs have a single output, RNNs have multiple
- [ ] In addition to the H output, RNNs have a cell state that runs across all cells 
- [ ] LSTMs have multiple outputs, RNNs have a single one

**Question 2**<br>
If you want to clear out all temporary variables that tensorflow might have from previous sessions, what code do you run?
- [ ] tf.keras.clear_session
- [ ] tf.cache.backend.clear_session()
- [ ] tf.cache.clear_session()
- [x] tf.keras.backend.clear_session()  

**Question 3**<br>
What does a Lambda layer in a neural network do?
- [ ] Changes the shape of the input or output data
- [x] Allows you to execute arbitrary code while training
- [ ] There are no Lambda layers in a neural network
- [ ] Pauses training without a callback

**Question 4**<br>
If X is the standard notation for the input to an RNN, what are the standard notations for the outputs?
- [ ] Y
- [ ] H
- [x] Y(hat) and H
- [ ] H(hat) and Y

**Question 5**<br>
A new loss function was introduced in this module, named after a famous statistician. What is it called?
- [ ] Hubble loss
- [x] Huber loss
- [ ] Hyatt loss
- [ ] Hawking loss

**Question 6**<br>
What is a sequence to vector if an RNN has 30 cells numbered 0 to 29
- [ ] The average Y(hat) for all 30 cells
- [ ] The total Y(hat) for all cells
- [ ] The Y(hat) for the second cell
- [x] The Y(hat) for the last cell

**Question 7**<br>
What does the axis parameter of tf.expand_dims do?
- [ ] Defines the dimension index to remove when you expand the tensor
- [ ] Defines if the tensor is X or Y
- [ ] Defines the axis around which to expand the dimensions
- [x] Defines the dimension index at which you will expand the shape of the tensor 

**Question 8**<br>
What happens if you define a neural network with these three layers?
```
tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
tf.keras.layers.Dense(1),
```
- [x] Your model will fail because you need return_sequences=True after the first LSTM layer
- [ ] Your model will fail because you have the same number of cells in each LSTM
- [ ] Your model will compile and run correctly
- [ ] Your model will fail because you need return_sequences=True after each LSTM layer
