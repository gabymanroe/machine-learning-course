**Question 1**<br>
![Screenshot_46](https://github.com/user-attachments/assets/bb1463ec-d0b4-4013-bee8-6ebfcf0701fe)<br>
For the random forest, how do you build each individual tree so that they are not all identical to each other?
- [x] Sample the training data with replacement and select a random subset of features to build each tree
- [ ] If you are training B trees, train each one on 1/B of the training set, so each tree is trained on a distinct set of examples. 
- [ ] Sample the training data without replacement
- [ ] Train the algorithm multiple times on the same training set. This will naturally result in different trees. 

**Question 2**<br>
You are choosing between a decision tree and a neural network for a classification task where the input x is a 100x100 resolution image. Which would you choose?
- [ ] A neural network, because the input is structured data and neural networks typically work better with structured data. 
- [x] A neural network, because the input is unstructured data and neural networks typically work better with unstructured data. 
- [ ] A decision tree, because the input is unstructured and decision trees typically work better with unstructured data. 
- [ ] A decision tree, because the input is structured data and decision trees typically work better with structured data. 

**Question 3**<br>
What does sampling with replacement refer to?
- [x] Drawing a sequence of examples where, when picking the next example, first replacing all previously drawn examples into the set we are picking from. 
- [ ] It refers to a process of making an identical copy of the training set. 
- [ ] Drawing a sequence of examples where, when picking the next example, first remove all previously drawn examples from the set we are picking from. 
- [ ] It refers to using a new sample of data that we use to permanently overwrite (that is, to replace) the original data. 
