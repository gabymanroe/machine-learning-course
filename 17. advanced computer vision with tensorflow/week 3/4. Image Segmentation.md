**Question 1**<br>
At the heart of image segmentation with neural networks is an encoder/decoder architecture. What functionalities do they perform ? 
- [ ] The decoder extracts features from an image and the encoder takes those extracted features, and assigns class label to the entire image.
- [ ] The encoder extracts features from an image and the decoder takes those extracted features, and assigns class label to the entire image.
- [ ] The decoder extracts features from an image and the encoder takes those extracted features, and assigns class labels to each pixel of the image.
- [x] The encoder extracts features from an image and the decoder takes those extracted features, and assigns class labels to each pixel of the image.

**Question 2**<br>
Is the following statement true regarding SegNet, UNet and Fully Convolutional Neural Networks (FCNNs):<br>
_Unlike the similarity between the architecture design of SegNet & UNet, FCNNs do not have a symmetric architecture design._
- [x] True
- [ ] False

**Question 3**<br>
What architectural difference does the numberrepresent in the names of FCN-32, FCN-16, FCN-8 ?
- [ ] The number represents the total number of pooling layers used in the architecture to help make predictions.
- [x] The number represents the factor by which the final pooling layer in the architecture up-samples the image to make predictions.
- [ ] The number represents the total number of convolutional layers used in the final pooling layer in the architecture to make predictions.
- [ ] The number represents the total number of filters used in the final pooling layer in the architecture to make predictions.

**Question 4**<br>
Take a look at the following code and select the type of scaling that will be performed<br>
![image](https://github.com/user-attachments/assets/99cc9786-66ae-4de6-90e4-ae28eb53fdb3)
- [x] The upsampling of the image will be done by means of linear interpolation from the closest pixel values
- [ ] The upsampling of the image will be done by copying the value from the closest pixels.

**Question 5**<br>
What does the following code do?<br>
![image](https://github.com/user-attachments/assets/a4ffb240-6047-4ac1-acb0-d9949e61c9f8)
- [ ] It takes pixel values in the image, in a 3x3 array, and using the specified filters, creates a transpose of that array.
- [x] It takes the pixel values and filters and tries to reverse the convolution process to return back a 3x3 array which could have been the original array of the image.

**Question 6**<br>
The following is the code for the last layer of a FCN-8 decoder. What key change is required if we want this to be the last layer of a FCN-16 decoder ? <br> 
![image](https://github.com/user-attachments/assets/958adc4a-f714-4738-b511-f0ac14226437)
- [ ] strides=(16, 16)
- [ ] Using sigmoid instead of softmax.
- [x] kernel_size=(16, 16)
- [ ] n_classes=16

**Question 7**<br>
Which of the following is true about Intersection Over Union (IoU) and Dice Score, when it comes to evaluating image segmentation? (Choose all that apply.)
- [x] Both have a range between 0 and 1
- [ ] For both, IoU & Dice Score the denominator is the total area of both the labels, predicted and ground truth
- [ ] Unlike IoU, for Dice Score the closer the value is to 0 the closer the prediction is to the ground truth.
- [x] For IoU the numerator is the area of overlap for both the labels, predicted and ground truth, whereas for Dice Score the numerator is 2 times that.

**Question 8**<br>
Consider the following code for building the encoder blocks for a U-Net. What should this function return?<br>
![image](https://github.com/user-attachments/assets/1016c660-cc7d-4a94-9e96-69ae18cf6edd)
- [ ] after_dropout, after_pooling (you need to return after_pooling to be used in skip connections)
- [ ] blocks
- [x] blocks, after_dropout
- [ ] after_dropout

**Question 9**<br>
For U-Net, on the decoder side you combine skip connections which come from the corresponding level of the encoder. Consider the following code and provide the missing line required to account for those skip connections with the upsampling.<br>
(Important Notes: Use TensorFlow as tf, Keras as keras. And be mindful of python spacing convention, i.e (x, y) not (x,y) )<br>
![image](https://github.com/user-attachments/assets/0116c98f-678e-4a4d-a1bd-29403e51a171)
> tf.keras.layers.concatenate([upsampling_layer, conv_output])
