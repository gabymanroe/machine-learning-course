**Question 1**<br>
To what file do you add the tensorflow lite dependency when building an Android app?
- [x] build.gradle
- [ ] gradle.build
- [ ] aar.gradle
- [ ] build.aar

**Question 2**<br>
If the Android Neural networks API is available and you want to use it, how would you do that?
- [x] Call the setUseNNAPI method on the interpreter and set its parameter to true
- [ ] Invoke the NNAPI object, and pass the tflite interpreter to it
- [ ] Do nothing, it will work automatically
- [ ] You can’t use the neural networks API with a TensorFlow Lite model

**Question 3**<br>
If you want to configure the number of threads the interpreter uses, how would you do that?
- [ ] Do nothing, it’s always single threaded
- [ ] Do nothing, it automatically picks the appropriate number of threads
- [ ] Call the useThreads() method, and it will apportion the correct number of threads
- [x] Call setNumThreads and pass it the number of threads you want to use

**Question 4**<br>
Where’s the best place in an Android app to keep your model?
- [ ] You don’t keep your model in your android App, it should download it at runtime
- [ ] In the same folder as the activity that calls it
- [x] It can really be anywhere, but for consistency use the assets folder
- [ ] In the resources folder

**Question 5**<br>
If you tested your converted model and know its valid, but the interpreter cannot load it at runtime on Android, what’s the most likely reason?
- [x] You didn’t specify that the model should not be compressed in the build.gradle file
- [ ] You haven’t quantized your model
- [ ] You have’t converted the model to Java or Kotlin format
- [ ] You converted your model to iOS format by accident

**Question 6**<br>
What is the method signature of the interpreter when you want to do inference?
- [ ] interpreter.predict(inputs, predictions)
- [x] interpreter.run(inputs, predictions)
- [ ] predictions = interpreter.run(inputs)
- [ ] predicitons = interpreter.predict(inputs)

**Question 7**<br>
What Android data structure is most commonly used to feed image input to the interpreter?
- [ ] A Tensor
- [ ] An Array
- [x] A ByteBuffer
- [ ] A TensorArray

**Question 8**<br>
How many classes of object can a model trained on the COCO dataset recognize?
- [ ] 10
- [x] 80
- [ ] 800
- [ ] 1000

**Question 9**<br>
When performing object recognition, how many dimensions of output tensors are there?
- [ ] 1
- [ ] 80
- [ ] 10
- [x] 4

**Question 10**<br>
How do you get the coordinates of the bounding boxes from the object detection model?
- [ ] The coordinates are in tensors 0, 1, 2 and 3
- [ ] The coordinates are in the first four tensors, read them and simply plot
- [ ] The coordinates are in the first tensor, read them and simply plot
- [x] The coordinates are in the first tensor, but arranged differently, you have to sort them before you can plot them
