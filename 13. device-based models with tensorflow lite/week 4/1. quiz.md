**Question 1**<br>
Which Devices support TensorFlow Lite for Inference? (Check all that apply)
- [x] Raspberry Pi
- [x] Sparkfun Edge
- [ ] RISC
- [x] Coral

**Question 2**<br>
With a Raspberry Pi, how can you use TensorFlow?
- [ ] Inference Only
- [ ] Training Only
- [ ] It doesn’t work on Pi
- [x] Inference and Training

**Question 3**<br>
If you only want to do inference on a Pi, what’s the best way?
- [ ] Do nothing, the Pi base image has TensorFlow in it
- [ ] Install the full TensorFlow with Pip install
- [x] Install the standalone interpreter using pip
- [ ] Compile all of TensorFlow from Source and run it

**Question 4**<br>
When using ImageNet on a Raspberry Pi for Image Classification, how many classes are supported?
- [ ] 500
- [ ] 100
- [x] 1000
- [ ] 800

**Question 5**<br>
How do you initialize the standalone interpreter in Python?
- [ ] tf.lite.load(lite_model)
- [x] tf.lite.Interpreter(directory_of_lite_Model)
- [ ] tf.lite.load(saved_model)
- [ ] tf.lite.Interpreter(directory_of_saved_model)

**Question 6**<br>
How do you get the input tensors for a model with the standalone interpreter?
- [ ] Call get_input_tensors() after calling allocate_tensors() on the interpreter
- [ ] Call get_input_details() after initializing the interpreter
- [x] Call get_input_details() after calling allocate_tensors() on the interpreter       
- [ ] Call get_input_tensors() after initializing the interpreter

**Question 7**<br>
How do you perform inference using the interpreter?
- [ ] Call invoke(), and pass it both the input and output tensors
- [ ] Just call invoke(), TensorFlow can do the rest
- [ ] Call invoke(), and pass it the input tensor
- [x] Set the Input tensor with the set_tensor command and then call invoke()

**Question 8**<br>
How do you read the results of inference using the interpreter?
- [ ] Call invoke(), pass it the input and output tensors, and then read the output tensor
- [x] Call invoke(), and then call get_tensor() on the interpreter to read the output
- [ ] Call invoke(), pass it the input tensor, read the results
- [ ] Call invoke(), and the the output will be rendered automatically
